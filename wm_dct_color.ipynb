{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73ece6-281f-4a8a-a628-bb6fa76b2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# file address in google drive\n",
    "file_root = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c20ba-82e9-40aa-8d10-ecb13b52e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e136f-bdc5-4740-964c-8091bfa1fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ebb7d-a573-44e5-91c7-92fa9bb3c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_img(x):\n",
    "    return (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30c06d-b5aa-47ca-9fd9-196564991709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltshow(img,gray=False):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.axis('off')\n",
    "    if(gray):\n",
    "        plt.imshow(img,cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02741384-2645-4541-956a-f4b3f083cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and show original image\n",
    "img = cv2.imread('%sbeagle0.jpg'%file_root)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load and show watermark image\n",
    "wm = cv2.imread('%savatar2.jpg'%file_root)\n",
    "wm = cv2.cvtColor(wm,cv2.COLOR_BGR2RGB)\n",
    "wm = cv2.resize(wm,dsize=(800,800),fx=1,fy=1,interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04775f5b-9bd4-4568-bfae-15a5bdd99c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add border to image so that it can be divided perfectly with block_size\n",
    "def addborder(img,block_size=4):\n",
    "    diff_x = img.shape[0] % block_size\n",
    "    diff_y = img.shape[1] % block_size\n",
    "    if (diff_x==0 and diff_y==0):\n",
    "        return img\n",
    "    img = cv2.copyMakeBorder(img,\n",
    "              0,(block_size-diff_x),\n",
    "              0,(block_size-diff_y),\n",
    "              cv2.BORDER_REPLICATE)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b71b5-3d24-4e9d-8691-bd71dcbd2a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform an image from original image to dct blocks\n",
    "# param bk: a 2-dim numpy array\n",
    "# param block_size: int\n",
    "def dct_img(bk,block_size=4):\n",
    "    img_dct_blocks_h = bk.shape[0] // block_size\n",
    "    img_dct_blocks_w = bk.shape[1] // block_size\n",
    "    img_dct = np.zeros(shape = (bk.shape[0],bk.shape[1]))\n",
    "    for h in range(img_dct_blocks_h):\n",
    "        print('\\r',h,end='',flush=True)\n",
    "        for w in range(img_dct_blocks_w):\n",
    "            a_block = bk[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size]\n",
    "            img_dct[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size] =\\\n",
    "            cv2.dct(a_block.astype(np.float64))\n",
    "    return img_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b746039-c36f-4024-9ca1-196557cc223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover an image from frequency domain to spatial domain\n",
    "# param bk: a 2-dim numpy array\n",
    "# param block_size: int\n",
    "def idct_img(bk,block_size=4):\n",
    "    img_dct_blocks_h = bk.shape[0] // block_size\n",
    "    img_dct_blocks_w = bk.shape[1] // block_size\n",
    "    img_idct = np.zeros(shape = (bk.shape[0],bk.shape[1]))\n",
    "    for h in range(img_dct_blocks_h):\n",
    "        for w in range(img_dct_blocks_w):\n",
    "            a_block = bk[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size]\n",
    "            img_idct[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size] =\\\n",
    "            cv2.idct(a_block.astype(np.float64))\n",
    "    return img_idct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addf7fb-5542-4e8e-b5ef-cc44de780f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_wm(img,wm,block_size=4,alpha=0.1):\n",
    "    res = np.zeros(shape=(img.shape))\n",
    "    for ch in range(3):\n",
    "        i_ch = img[...,ch]\n",
    "        w_ch = wm[...,ch]\n",
    "        f_ch = dct_img(i_ch,block_size=block_size)\n",
    "        # w_f_ch = dct_img(w_ch,block_size=block_size)\n",
    "        # f_ch_new = f_ch + alpha*w_f_ch\n",
    "        f_ch_new = f_ch + alpha*w_ch\n",
    "        i_ch_new = idct_img(f_ch_new,block_size=block_size)\n",
    "        res[...,ch] = i_ch_new\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1afe78-a23b-4e79-86a5-0577d66c2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wm(wmed_img,img,block_size=4,alpha=0.1):\n",
    "    wmed_dct = np.zeros_like(wmed_img)\n",
    "    img_dct = np.zeros_like(img)\n",
    "    wm = np.zeros_like(img)\n",
    "    for ch in range(3):  \n",
    "        wmed_dct[...,ch] = dct_img(wmed_img[...,ch],block_size=block_size)\n",
    "        img_dct[...,ch] = dct_img(img[...,ch],block_size=block_size)\n",
    "        wm[...,ch] = (wmed_dct[...,ch]-img_dct[...,ch]) / alpha\n",
    "    return wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cbc44-8a26-41b4-98ed-71f80197983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wmed_img = embed_wm(img,wm,alpha=0.01)\n",
    "# #wmed_img = np.clip(wmed_img,0,255)\n",
    "# pltshow(norm_img(wmed_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad11e19-8c7a-484e-853e-e973f17dbfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wm_extract = extract_wm(wmed_img,img,alpha=0.01)\n",
    "# pltshow(wm_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7896f1e2-2056-4f96-be52-799d9cae826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805e716-4b74-42f6-9300-23878b8a83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and show watermark image\n",
    "wm = cv2.imread('%secnu.jpg'%file_root)\n",
    "wm = cv2.cvtColor(wm,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541731df-6ebd-4394-8abf-371a7194d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_beagle = cv2.imread('%sbeagle0.jpg'%file_root)\n",
    "img_beagle = cv2.cvtColor(img_beagle,cv2.COLOR_BGR2RGB)\n",
    "wm_beagleresize = cv2.resize(wm,dsize = (960,1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af5898-c451-4ccc-8d33-4c065a2645a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmed_beagle = embed_wm(img_beagle,wm_beagleresize,alpha=alpha)\n",
    "pltshow(norm_img(wmed_beagle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf1e7eb-e17a-435d-b68c-d2791b5f9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_wm = extract_wm(wmed_beagle,img_beagle)\n",
    "pltshow(extracted_wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d818c-1e11-43de-9ba9-a5048eaa0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check classification result for single image\n",
    "# param model: torch model\n",
    "# param file_path: image file path\n",
    "# param transform: torchvision.transforms\n",
    "def check_classify_path(model,file_path,transform):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = torch.unsqueeze(transform(img),0).cuda()\n",
    "    out = (F.softmax(model(img),dim=1))\n",
    "    print(torch.max(out))\n",
    "    print(out.argmax())\n",
    "# check classification result for single image\n",
    "# param model: torch model\n",
    "# param img: 3-dim image array\n",
    "# param transform: torchvision.transforms\n",
    "def check_classify_array(model,img,transform):\n",
    "    img = torch.unsqueeze(transform(img),0)\n",
    "    img = img.type(torch.FloatTensor)\n",
    "    img = img.cuda()\n",
    "    out = (F.softmax(model(img),dim=1))\n",
    "    print(torch.max(out))\n",
    "    print(out.argmax())\n",
    "# check classification result for single image\n",
    "# param model: torch model\n",
    "# param img: 4-dim image tensor\n",
    "def check_classify_tensor(model,img):\n",
    "    out = (F.softmax(model(img),dim=1))\n",
    "    print(torch.max(out))\n",
    "    print(out.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6364a10-8a1d-4081-93df-6365173db750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image tranformation\n",
    "T_3 = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize([256,256]),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "T_2 = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize([256,256])\n",
    "])\n",
    "T = transforms.ToTensor()\n",
    "\n",
    "img_tensor =  T(img)\n",
    "img_tensor = img_tensor.cuda()\n",
    "wm_tensor = T(wm)\n",
    "wm_tensor = wm_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea513a-e919-44b1-9cda-572f0a788f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_dct as dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4490f202-1297-4f1d-82a2-c1e7923fabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t_dct = torch.stack((dct.dct_2d(img_tensor[0,...]),dct.dct_2d(img_tensor[1,...]),dct.dct_2d(img_tensor[2,...])),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c75cf-519f-4e4d-8fe1-3d37b50c5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL(img_t_dct).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e124de1-ec79-4960-ab52-e9d4abf842aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t_idct = torch.stack((dct.idct_2d(img_t_dct[0,...]),dct.idct_2d(img_t_dct[1,...]),dct.idct_2d(img_t_dct[2,...])),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113fb3b-25f2-4dea-b5ea-d8a5c61b46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68504644-d754-4422-9596-ec1ce3f41d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dfab6-572a-40b3-b92b-807dfd021381",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL(img_t_idct).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c7444-a6f8-4283-adcb-1b08e2e6eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_tensor = T(wm_beagleresize)\n",
    "wm_tensor = wm_tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657e9e0-9699-48ff-8264-0f7f1c7b902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3f97ee-d105-4e5c-8ee0-6717d9176641",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t_dct_wm = img_t_dct + alpha*wm_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fc072-0342-46e8-b1af-5901ce9a436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t_idct_wm = torch.stack((dct.idct_2d(img_t_dct_wm[0,...]),dct.idct_2d(img_t_dct_wm[1,...]),dct.idct_2d(img_t_dct_wm[2,...])),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99146e53-d06c-469c-bbf9-c7779b998a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672bddf-058b-4558-96d9-cb775c5b324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_tensor(img):\n",
    "    return torch.stack((dct.dct_2d(img[0,...]),dct.dct_2d(img[1,...]),dct.dct_2d(img[2,...])),dim=0)\n",
    "\n",
    "def idct_tensor(img):\n",
    "    return torch.stack((dct.idct_2d(img[0,...]),dct.idct_2d(img[1,...]),dct.idct_2d(img[2,...])),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708bb6dd-11b7-46f7-8f30-efd00dca824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmed_img = img_t_idct_wm.clip(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4010bf9-bf4c-4e8b-ba0b-f4b6c39271fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmed_dct = dct_tensor(wmed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e21f09-8a6c-44d3-b8e8-020c5511e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (wmed_dct-img_t_dct)/alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027fb87-7ced-4c66-b762-58ea7b56d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL(diff).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d1623-9d07-47bb-ab69-6a08e41fda61",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL(img_t_idct_wm).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373aae53-361f-4080-baeb-b451c6c9a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = cv2.dct(img[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size,0].astype(np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d02d7d-13b0-46d7-a464-4b54bce6cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = dct.dct_2d(img_tensor[0,h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85b7c8-0eea-4c25-af03-96070ebc7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = dct.dct_2d(img_tensor[2,...])\n",
    "toPIL(i0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eab2330-fad0-4a86-a089-d369c4ab3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 4\n",
    "img_dct = torch.tensor(np.zeros((img.shape[2],img.shape[0],img.shape[1])))\n",
    "img_dct = img_dct.cuda()\n",
    "for ch in range(3):\n",
    "    bk = img_tensor[ch,...]\n",
    "    img_dct_blocks_h = bk.shape[0] // block_size\n",
    "    img_dct_blocks_w = bk.shape[1] // block_size\n",
    "    bk_dct = torch.tensor(np.zeros_like(img[...,ch]))\n",
    "    bk_dct = bk_dct.cuda()\n",
    "    for h in range(img_dct_blocks_h):\n",
    "        print('\\r',h,end='',flush=True)\n",
    "        for w in range(img_dct_blocks_w):\n",
    "            a_block = bk[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size]\n",
    "            bk_dct[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size] =\\\n",
    "            dct.dct_2d(a_block)\n",
    "    img_dct[ch,...] = bk_dct\n",
    "toPIL(img_dct).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4018fbc-883d-42f4-a954-e6008c082f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 4\n",
    "img_idct = torch.tensor(np.zeros((img.shape[2],img.shape[0],img.shape[1])))\n",
    "img_idct = img_dct.cuda()\n",
    "for ch in range(3):\n",
    "    bk = img_dct[ch,...]\n",
    "    img_dct_blocks_h = bk.shape[0] // block_size\n",
    "    img_dct_blocks_w = bk.shape[1] // block_size\n",
    "    bk_idct = torch.tensor(np.zeros_like(img[...,ch]))\n",
    "    bk_idct = bk_dct.cuda()\n",
    "    for h in range(img_dct_blocks_h):\n",
    "        print('\\r',h,end='',flush=True)\n",
    "        for w in range(img_dct_blocks_w):\n",
    "            a_block = bk[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size]\n",
    "            bk_idct[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size] =\\\n",
    "            dct.idct_2d(a_block)\n",
    "    img_idct[ch,...] = bk_idct\n",
    "toPIL(img_dct).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff8f8a-4d18-4743-978f-6834adb1c940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fbed5-fbf2-4900-abcd-c08f1b6d1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = toPIL(wm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfecc0a-ed41-4732-8d1b-ddd965f8062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770c1b6-29ed-4033-9064-64dff8fd28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_block[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db68a21-5c0e-4b66-8c8f-08ce24b6dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct_img_tensor(bk,block_size=4):\n",
    "    img_dct_blocks_h = bk.shape[0] // block_size\n",
    "    img_dct_blocks_w = bk.shape[1] // block_size\n",
    "    img_dct = np.zeros(shape = (bk.shape[0],bk.shape[1]))\n",
    "    for h in range(img_dct_blocks_h):\n",
    "        for w in range(img_dct_blocks_w):\n",
    "            a_block = bk[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size]\n",
    "            img_dct[h*block_size:(h+1)*block_size,w*block_size:(w+1)*block_size] =\\\n",
    "            cv2.dct(a_block.astype(np.float64))\n",
    "    return img_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a7194-5ebe-43df-bd1f-f59acc8dd624",
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL(img_tensor).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e0820-0c62-4cbf-a210-9d2c5c5aaaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7994709b-4e5b-4fef-919f-e725652e69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tensor to PILImage (for presentation)\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873023e2-cb2d-4437-a9aa-225d10b152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torch import nn\n",
    "from typing import Optional, Any, List, Callable, Type, Union\n",
    "from torchvision.models.resnet import BasicBlock,Bottleneck\n",
    "class ResNet_with_trans(ResNet):\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = transforms.Resize([256,256])(x)\n",
    "        x = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(x)\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "from torchvision.models._utils import _ovewrite_named_param\n",
    "def resnet50_with_trans(*, weights: Optional[ResNet50_Weights] = None, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "    weights = ResNet50_Weights.verify(weights)\n",
    "    # model = _resnet(Bottleneck, [3, 4, 6, 3], weights, progress, **kwargs)\n",
    "    block = Bottleneck\n",
    "    layers = [3, 4, 6, 3]\n",
    "\n",
    "    if weights is not None:\n",
    "        _ovewrite_named_param(kwargs, \"num_classes\", len(weights.meta[\"categories\"]))\n",
    "\n",
    "    model = ResNet_with_trans(block, layers, **kwargs)\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_state_dict(weights.get_state_dict(progress=progress))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054c65a2-28c3-4b36-9e78-9ee6baeafea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f7c1f-0d54-46e2-b1aa-139c7c2ee627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_and_check(model,T,atk,img,target):\n",
    "    origin = torch.unsqueeze(T(img),0)\n",
    "    origin = origin.type(torch.FloatTensor)\n",
    "    origin = origin.cuda()\n",
    "    adv_images = atk(origin, target)\n",
    "    out_per = (F.softmax(model(adv_images),dim=1))\n",
    "    print(torch.max(out_per))\n",
    "    print(out_per.argmax())\n",
    "    adv_image = show(adv_images.cpu().detach()[0])\n",
    "    # adv_image.show()\n",
    "    return np.array(adv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8473b-a785-4b8b-8b52-39a58fcbd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet50_with_trans(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet = resnet.cuda()\n",
    "resnet = resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d2f10-8ed9-4a93-a3f4-f0b0f71e4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmed_beagle = np.clip(wmed_beagle,0,255)\n",
    "pltshow(norm_img(wmed_beagle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f12f6a-4bd5-46f8-8b0a-6d38a1868198",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_ = extract_wm(wmed_beagle,img_beagle,alpha=0.1)\n",
    "pltshow(norm_img(ex_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c61f6ba-bc5d-421d-849e-f067729c810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmed_beagle = embed_wm(img_beagle,wm_beagleresize,alpha=alpha)\n",
    "wmed_beagle = np.clip(wmed_beagle,0,225)\n",
    "wmed_beagle = norm_img(wmed_beagle)\n",
    "pltshow(wmed_beagle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe87a7-951e-48c9-8887-2cb5a642f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_classify_array(resnet,wmed_beagle,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2194b99-9dff-4d0f-a482-b34138c49b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([162]).cuda()\n",
    "cw_atk = torchattacks.CW(resnet, c=1, kappa=0, steps=100, lr=0.01)\n",
    "cw_beagle = attack_and_check(resnet,T,cw_atk,wmed_beagle,target)\n",
    "pltshow(cw_beagle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6164323-4e93-409a-9642-a14afda8b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([162]).cuda()\n",
    "gamma = 1/255\n",
    "pgd_atk = torchattacksattack = torchattacks.PGD(resnet, eps=8/255, alpha=gamma, steps=40, random_start=True)\n",
    "pgd_beagle = attack_and_check(resnet,T,pgd_atk,wmed_beagle,target)\n",
    "pltshow(pgd_beagle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddca6e6-ea51-47c5-8d44-4c7fa7904408",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = (pgd_beagle-wmed_beagle)/gamma\n",
    "\n",
    "per_dct = np.stack((dct_img(per[...,0]),\n",
    "                    dct_img(per[...,1]),\n",
    "                    dct_img(per[...,2])),\n",
    "                   axis=2)\n",
    "\n",
    "wm_per = per_dct * (gamma/alpha)\n",
    "\n",
    "wm_perturbed = wm_per+wm_beagleresize\n",
    "\n",
    "wm_perturbed = np.clip(wm_perturbed,0,225)\n",
    "pltshow(norm_img(wm_perturbed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f51eb-c9b4-489b-8fe7-c3046973bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmpered_beagle = embed_wm(img_beagle,wm_perturbed,alpha=alpha)\n",
    "wmpered_beagle = np.clip(wmpered_beagle,0,225)\n",
    "wmpered_beagle = norm_img(wmpered_beagle)\n",
    "pltshow(wmed_beagle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e4ad1-8e98-4c12-8b72-7591e050e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_classify_array(resnet,wmpered_beagle,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de94dc81-1451-401f-a287-ad074758cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_and_check(model,T,atk,img,target):\n",
    "  origin = torch.unsqueeze(T(img),0).cuda()\n",
    "  adv_images = atk(origin, target)\n",
    "  out_per = (F.softmax(model(adv_images),dim=1))\n",
    "  print(torch.max(out_per))\n",
    "  print(out_per.argmax())\n",
    "  adv_image = show(adv_images.cpu().detach()[0])\n",
    "  # adv_image.show()\n",
    "  return np.array(adv_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hancy",
   "language": "python",
   "name": "hancy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

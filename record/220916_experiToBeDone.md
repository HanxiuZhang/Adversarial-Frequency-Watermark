# Experiments in existing papers
## Digital Watermark Perturbation for Adversarial Examples to Fool Deep Neural Networks
- Randomly select 1000 images from ImageNet and 1000 images from CIFAR-10 to complete the experiments
- Test on AlexNet, VGG19, SqueezeNet, Resnet101 and Inception V3
- Attack success rates
- PSNR
- Performance on the image transformation defense methods: random rotation, random cropping, JPEG compression, and random padding
- Transferability of Adversarial Examples
## Digital Watermarking as an Adversarial Attack on Medical Image Analysis with Deep Learning
- DenseNet169, DenseNet201, and MobileNetV2
- FGSM, PGD, and Square Attack for comparision
- SSIM index was calculated for the assessment of the image distortion
- Ablation Study
# Experiments TODO
## Dataset
cifar-10 imagenet1000
## Model
resnet50 alexnet vgg19 MobileNetV2 DenseNet201
## Watermark image
- change bk black √
- ecnu-logo √
- ecnu-text √
## Attack method to combine
- FGSM
- PGD
- grad-based atk A
## Attack method to compare
(compare distortion)
- FGSM
- PGD
- grad-based atk A
- CW 
- *gaussian noise*
## Defense method
(also influence on wm)
random rotation, random cropping, JPEG compression, and random padding
## As defense method for watermarking-based defense"??
---
## 2022.9.19
- code 5 models
- train 5 model for cifar-10
- read 2 wm-based defense papers